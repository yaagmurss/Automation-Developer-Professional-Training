# ***UiPath Document Understanding Overview***

Document understanding : The ability to extract and interpret information and meaning from a wide range of document types, storage formats (e.g., images, PDFs), and objects (e.g., handwriting, signatures, checkboxes, logos).


There are three types of documents: 

- Structured documents, or forms (Surveys, questionnaires, Tax forms, passports, licenses, and time sheets. These contain exclusively key-value pairs and tables),
- Semi-structured documents (Invoices, Receipts, Purchase Orders, Healthcare lab reports, bank statements and utility bills),
- Unstructured documents (contracts, leases, Annual Reports, agreements, and news).


A typical Document Understanding workflow goes through four fundamental steps namely:



- ***Digitization*** : Digitization is the process of obtaining the machine-readable text from a given incoming file so that a robot can then digitally process it.



- ***Classification*** : After digitization, the document is classified. In a real-life scenario, there are multiple document types, so the robot needs to know what type of document they're working with to extract data properly.There are different viable strategies for this, but the highest-performing ones tend to involve AI.



- ***Extraction*** : Extraction is getting just the data you're interested in.In document understanding, once the document has been classified, a robot is able to recognize the relevant fields and extract the data in a structured manner. 



- ***Validation and Human in the loop*** : In doing classification and extraction, software robots use the concept of confidence, which measures how 'sure' the robot is that they performed a certain task well, whether it is recognizing a document type, identifying a field, or reading the data in it.In these cases, the document understanding framework offers the possibility to engage a human user to review and validate the robot's output. 



---



***Digitization***


- It detects all the words in the document and their x-y coordinates, whether by doing OCR - Optical Character Recognition (for scanned PDFs) or by getting the text directly from the native PDF documents.

- When documents are in native PDF, OCR is typically not required.

- It can also detect other things on documents, such as handwritten text, checkboxes, signatures, or barcodes/QR codes, depending on the OCR engine used.

- OCR is able to extract text and metadata from the documents.


***The OCR engines that are available by default are the following:***


***UiPath Document OCR:*** Nearly all customers use UiPath Document OCR for printed text, checkboxes, handwritten text, signatures, barcodes, and QR codes.



***UiPath Chinese-Japanese-Korean OCR***
â€¢Print text;  Handwritten text.



***Kofax Omnipage activity packs*** (available as Studio activity package) for printed text.


![image](https://github.com/user-attachments/assets/bf5a2fc5-042d-4486-b552-2113c041fe93)


![image](https://github.com/user-attachments/assets/d73a17a3-5a4d-4495-90ec-2924cbf8d6f8)





---



***Classification***


- After digitization, the document is classified. In a project with multiple document types, you need to know what type of document you're working with, in order to extract data properly.

- The key thing here is that you can use multiple classifiers in the same scope, you can configure the classifiers and, later in the process, even train them. The classification results help in applying the right strategy in extraction.

- UiPath Document Understanding offers different classification capabilities ranging from keyword-based to ML-based classification.




![1](https://github.com/user-attachments/assets/7a51df8c-44a0-4b7c-86a9-8df5aa72c1bb)



---


***Extraction***


- Extraction is getting just the data you're interested in. For example, extracting specific data from a 5-page document is quite troublesome if you want to do it with string manipulation. But in the Document Understanding framework, you can use different extractors for the different document structures, in the same scope application. The extraction results are passed further for validation.

There are four extraction methods available:

- Regex Extractor

- Form Extractor

- Forms AI

- Semi-structured AI.



![2](https://github.com/user-attachments/assets/81e5fcc3-fe9f-41f2-a759-855bc41e04b1)




***Pre-trained out-of-the-box extractors***

The out-of-the-box ML extractors are models that have already been trained and deployed by the UiPath Data Scientists. 
They can be leveraged by simply referencing them from the ML Extractor, inside the Data Extraction Scope activity, and don't require any additional setup.


***Advantages of using the out-of-the-box models***

- The biggest advantage of out-of-the-box models is that you can start processing documents with them right away.

- The extractors accept files in PDF, PNG, JPEG, and TIFF formats and can automatically determine the location of critical pieces of information even if the format of the document changes.

- They don't require any templates and can automatically identify and extract a wide range of entities from your documents. Even if the documents include "noise," the models will still find and extract the relevant information.




***Out of the many such models available, the following are the two of them:***

- Invoices ML Extractor: This model is suitable for processing invoices in English, Spanish, Portuguese, German, and Romanian languages.

- Receipts ML Extractor: This model is suitable for processing receipts in English, Spanish, German, French, Norwegian, Finnish, and Romanian languages.

  

---



***Human Validation***


The Document Understanding framework offers the ability to detect potential errors and route the documents for human review. The UiPath Platform currently offers three kinds of user interfaces for doing manual validation for document processing:  

- ***1) Classification station or Validation station (in UiPath Action Center)***




  ![image](https://github.com/user-attachments/assets/cc8a8d87-5edf-404e-b2b2-a37458a335c1)


- ***2) Forms***
An alternative is to create Forms using the FormDesigner which allows the creation of complex forms including a pdf document viewer pane. These can be done using the UiPath.Form.Activities to be used with attended robot, or using the UiPath.Persistence.Activities.FormTask.CreateFormTask if you prefer managing tasks in Action Center.

- ***3) Apps***
If you desire a high degree of flexibility in customizing the validation interface and are willing to put in the required effort, you have the option to build a validation experience in UiPath Apps.




![image](https://github.com/user-attachments/assets/c01dfd93-0fb8-48a5-a0a6-5e9ac4728ce0)


---


# The UiPath Document Understanding first-party service

The UiPath Document Understanding first-party service is meant to be the interface with all the document understanding capabilities available in the UiPath Platform: building classifiers and extractors by training machine learning models, pre-labeling, labeling, and so on.



![image](https://github.com/user-attachments/assets/941b6bb6-d9b8-4b6d-a18e-3ea97067cbb4)





***The document understanding features in Studio***

To build document understanding automations in Studio, Automation Developers leverage several components:

1-The UiPath.IntelligentOCR activity package, containing the main activities needed in the Document Understanding framework.

2-The DocumentUnderstanding.ML activity package, enabling the use of ML extractors and their retraining.

3-The UiPath.OCR activities, consisting of the OCR engines used for digitization.

4-The Document Understanding process template, which is an automation process structure with built-in configurations and exception handling, meant for enterprise-level automation projects.

---


***The UiPath.IntelligentOCR activity package***

- The main Document Understanding framework activities are all found in the UiPath.IntelligentOCR activity package. 

- Once the package is installed, the Taxonomy Manager wizard appears in the top ribbon of the UiPath Studio.

- The scope activities (Classify Document Scope, Data Extraction Scope, Train Classifiers Scope, Train Extractors Scope) that are part of the Document Understanding framework allow you to use any document classification and data extraction algorithms that fit your use case and then train these algorithms.

![3](https://github.com/user-attachments/assets/59e306b2-130c-455d-bda6-335bfaa46683)


--

![4](https://github.com/user-attachments/assets/b57c0d98-bfed-445c-a52d-42e87d06cb1b)



--
![5](https://github.com/user-attachments/assets/81064844-2f87-4d9d-86c6-9874518101b1)



--

![6](https://github.com/user-attachments/assets/436d722a-5346-4670-bc14-56cbab6672e0)



--

![7](https://github.com/user-attachments/assets/aff00368-8c42-46c2-bc8f-d89c937b530a)



---





***The DocumentUnderstanding.ML activity package***
![8](https://github.com/user-attachments/assets/d87951a0-dad7-4ef1-aff1-f26520da206f)

ML Extractor

--
![9](https://github.com/user-attachments/assets/01ab2ea5-617b-4dfb-889a-f97695e6e312)


 ML Extractor Trainer


---

![image](https://github.com/user-attachments/assets/a2c79890-c7f1-449b-9736-eee74a79e243)


----




![image](https://github.com/user-attachments/assets/bc792468-cc4a-49cf-b1bf-692e2a4b5c4c)

---

***Note***


***Requirements***

- Need to access the UiPath Platform in either Automation Cloud or Automation Suite, ideally through an enterprise license. 

- At the minimum, you need UiPath Studio installed on your machine, access to the UiPath Document Understanding service in Automation Cloud/Suite, access to AI Center, as well as AI units.




























